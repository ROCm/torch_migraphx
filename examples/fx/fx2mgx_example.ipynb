{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIGraphX Accelerator Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "libpath = os.path.join(Path.cwd().parents[1],'py')\n",
    "sys.path.append(libpath)\n",
    "\n",
    "\n",
    "import torch\n",
    "import migraphx\n",
    "import torchvision.models as models\n",
    "from torch_migraphx.fx.fx2mgx import MGXInterpreter\n",
    "from torch_migraphx.fx.mgx_module import MGXModule\n",
    "import torch_migraphx.fx.tracer.acc_tracer.acc_tracer as acc_tracer\n",
    "from torch_migraphx.fx.tracer.acc_tracer.acc_shape_prop import AccShapeProp\n",
    "from torch_migraphx.fx.tools.mgx_splitter import MGXSplitter\n",
    "\n",
    "from torch.fft import fft2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a simple network we will lower to migraphx. It also contains an unsupported operation (fft2) we must handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self, k, in_ch):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_ch, in_ch * 2, k, padding='same')\n",
    "        self.bn = torch.nn.BatchNorm2d(in_ch * 2)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.linear = torch.nn.Linear(224 * 224 * in_ch * 2, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = fft2(x).abs()  #unsupported op\n",
    "        x = x.flatten(1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k, in_ch = 3, 3\n",
    "model = ConvNet(k, in_ch)\n",
    "model.eval()\n",
    "sample_inputs = [torch.randn(50, 3, 224, 224)]\n",
    "\n",
    "model = model.cuda()\n",
    "sample_inputs = [i.cuda() for i in sample_inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we use our custom fx tracer (acc_tracer) to generate a graph representation of the above module. The custom tracer also normalizes all supported torch operations to map to acc ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opcode         name             target                                   args         kwargs\n",
      "-------------  ---------------  ---------------------------------------  -----------  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "placeholder    x                x                                        ()           {}\n",
      "get_attr       conv_weight      conv.weight                              ()           {}\n",
      "get_attr       conv_bias        conv.bias                                ()           {}\n",
      "call_function  conv2d_1         <function conv2d at 0x7f4b3faae160>      ()           {'input': x, 'weight': conv_weight, 'bias': conv_bias, 'stride': (1, 1), 'padding': 'same', 'dilation': (1, 1), 'groups': 1}\n",
      "get_attr       bn_weight        bn.weight                                ()           {}\n",
      "get_attr       bn_bias          bn.bias                                  ()           {}\n",
      "get_attr       bn_running_mean  bn.running_mean                          ()           {}\n",
      "get_attr       bn_running_var   bn.running_var                           ()           {}\n",
      "call_function  batch_norm_1     <function batch_norm at 0x7f4b3faae940>  ()           {'input': conv2d_1, 'running_mean': bn_running_mean, 'running_var': bn_running_var, 'weight': bn_weight, 'bias': bn_bias, 'training': False, 'momentum': 0.1, 'eps': 1e-05}\n",
      "call_function  relu_1           <function relu at 0x7f4b3faae3a0>        ()           {'input': batch_norm_1, 'inplace': False}\n",
      "call_function  fft_fft2         <built-in function fft_fft2>             (relu_1,)    {'s': None, 'dim': [-2, -1], 'norm': None}\n",
      "call_method    abs_1            abs                                      (fft_fft2,)  {}\n",
      "call_function  flatten_1        <function flatten at 0x7f4b3faae5e0>     ()           {'input': abs_1, 'start_dim': 1}\n",
      "get_attr       linear_weight    linear.weight                            ()           {}\n",
      "get_attr       linear_bias      linear.bias                              ()           {}\n",
      "call_function  linear_1         <function linear at 0x7f4b3faae0d0>      ()           {'input': flatten_1, 'weight': linear_weight, 'bias': linear_bias}\n",
      "output         output           output                                   (linear_1,)  {}\n"
     ]
    }
   ],
   "source": [
    "#Trace model using custom tracer\n",
    "traced = acc_tracer.trace(model, sample_inputs)\n",
    "traced.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the graph into subgraphs that are supported by migraphx and ones that need to run via the torch implementation. Submodules named 'run_on_acc_{}' are marked to be lowered to migraphx and the ones named 'run_via_torch_{}' are marked to be executed though its original torch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Supported node types in the model:\n",
      "acc_ops.conv2d: ((), {'input': torch.float32, 'weight': torch.float32, 'bias': torch.float32})\n",
      "acc_ops.batch_norm: ((), {'input': torch.float32, 'running_mean': torch.float32, 'running_var': torch.float32, 'weight': torch.float32, 'bias': torch.float32})\n",
      "acc_ops.relu: ((), {'input': torch.float32})\n",
      "acc_ops.flatten: ((), {'input': torch.float32})\n",
      "acc_ops.linear: ((), {'input': torch.float32, 'weight': torch.float32, 'bias': torch.float32})\n",
      "\n",
      "Unsupported node types in the model:\n",
      "torch._C._fft.fft_fft2: ((torch.float32,), {})\n",
      "abs: ((torch.complex64,), {})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitter = MGXSplitter(traced, sample_inputs)\n",
    "_ = splitter.node_support_preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [#users=1] = placeholder[target=x]\n",
      "    %_run_on_acc_0 : [#users=1] = call_module[target=_run_on_acc_0](args = (%x,), kwargs = {})\n",
      "    %_run_via_torch_1 : [#users=1] = call_module[target=_run_via_torch_1](args = (%_run_on_acc_0,), kwargs = {})\n",
      "    %_run_on_acc_2 : [#users=1] = call_module[target=_run_on_acc_2](args = (%_run_via_torch_1,), kwargs = {})\n",
      "    return _run_on_acc_2\n"
     ]
    }
   ],
   "source": [
    "split_mod = splitter()\n",
    "print(split_mod.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : [#users=1] = placeholder[target=x]\n",
      "    %conv_weight : [#users=1] = get_attr[target=conv.weight]\n",
      "    %conv_bias : [#users=1] = get_attr[target=conv.bias]\n",
      "    %conv2d_1 : [#users=1] = call_function[target=torch_migraphx.fx.tracer.acc_tracer.acc_ops.conv2d](args = (), kwargs = {input: %x, weight: %conv_weight, bias: %conv_bias, stride: (1, 1), padding: same, dilation: (1, 1), groups: 1})\n",
      "    %bn_running_mean : [#users=1] = get_attr[target=bn.running_mean]\n",
      "    %bn_running_var : [#users=1] = get_attr[target=bn.running_var]\n",
      "    %bn_weight : [#users=1] = get_attr[target=bn.weight]\n",
      "    %bn_bias : [#users=1] = get_attr[target=bn.bias]\n",
      "    %batch_norm_1 : [#users=1] = call_function[target=torch_migraphx.fx.tracer.acc_tracer.acc_ops.batch_norm](args = (), kwargs = {input: %conv2d_1, running_mean: %bn_running_mean, running_var: %bn_running_var, weight: %bn_weight, bias: %bn_bias, training: False, momentum: 0.1, eps: 1e-05})\n",
      "    %relu_1 : [#users=1] = call_function[target=torch_migraphx.fx.tracer.acc_tracer.acc_ops.relu](args = (), kwargs = {input: %batch_norm_1, inplace: False})\n",
      "    return relu_1\n",
      "graph():\n",
      "    %relu_1 : [#users=1] = placeholder[target=relu_1]\n",
      "    %fft_fft2 : [#users=1] = call_function[target=torch._C._fft.fft_fft2](args = (%relu_1,), kwargs = {s: None, dim: [-2, -1], norm: None})\n",
      "    %abs_1 : [#users=1] = call_method[target=abs](args = (%fft_fft2,), kwargs = {})\n",
      "    return abs_1\n",
      "graph():\n",
      "    %abs_1 : [#users=1] = placeholder[target=abs_1]\n",
      "    %flatten_1 : [#users=1] = call_function[target=torch_migraphx.fx.tracer.acc_tracer.acc_ops.flatten](args = (), kwargs = {input: %abs_1, start_dim: 1})\n",
      "    %linear_weight : [#users=1] = get_attr[target=linear.weight]\n",
      "    %linear_bias : [#users=1] = get_attr[target=linear.bias]\n",
      "    %linear_1 : [#users=1] = call_function[target=torch_migraphx.fx.tracer.acc_tracer.acc_ops.linear](args = (), kwargs = {input: %flatten_1, weight: %linear_weight, bias: %linear_bias})\n",
      "    return linear_1\n"
     ]
    }
   ],
   "source": [
    "print(split_mod._run_on_acc_0.graph)\n",
    "print(split_mod._run_via_torch_1.graph)\n",
    "print(split_mod._run_on_acc_2.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert any submodules that are eligible to be lowered to migraphx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need sample inputs when lowering submodules\n",
    "def get_submod_inputs(mod, submod, inputs):\n",
    "    acc_inputs = None\n",
    "\n",
    "    def get_input(self, inputs):\n",
    "        nonlocal acc_inputs\n",
    "        acc_inputs = inputs\n",
    "\n",
    "    handle = submod.register_forward_pre_hook(get_input)\n",
    "    mod(*inputs)\n",
    "    handle.remove()\n",
    "    return acc_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, _ in split_mod.named_children():\n",
    "    if \"_run_on_acc\" in name:\n",
    "        submod = getattr(split_mod, name)\n",
    "        # Get submodule inputs for fx2trt\n",
    "        acc_inputs = get_submod_inputs(split_mod, submod, sample_inputs)\n",
    "        AccShapeProp(submod).propagate(*acc_inputs)\n",
    "\n",
    "        # fx2trt replacement\n",
    "        interp = MGXInterpreter(\n",
    "            submod,\n",
    "            acc_inputs\n",
    "        )\n",
    "        interp.run()\n",
    "        mgx_mod = MGXModule(interp.program, interp.get_input_names())\n",
    "\n",
    "        setattr(split_mod, name, mgx_mod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The creation of MGXModule automatically runs all optimization passes available in MIGraphX and stores the complied program. We can see the hip instructions by printing the stored programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module: \"main\"\n",
      "main:@0 = check_context::migraphx::version_1::gpu::context -> float_type, {}, {}\n",
      "main:@1 = hip::hip_allocate_memory[shape=float_type, {0}, {1},id=main:scratch] -> float_type, {0}, {1}\n",
      "main:@2 = hip::hip_copy_literal[id=main:@literal:1] -> float_type, {6}, {1}\n",
      "main:@3 = hip::hip_copy_literal[id=main:@literal:0] -> float_type, {6, 3, 3, 3}, {27, 9, 3, 1}\n",
      "main:#output_0 = @param:main:#output_0 -> float_type, {50, 6, 224, 224}, {301056, 50176, 224, 1}\n",
      "main:@5 = broadcast[axis=1,out_lens={50, 6, 224, 224}](main:@2) -> float_type, {50, 6, 224, 224}, {0, 1, 0, 0}\n",
      "x = @param:x -> float_type, {50, 3, 224, 224}, {150528, 50176, 224, 1}\n",
      "main:@7 = gpu::miopen_fusion[ops={{op=convolution[padding={1, 1, 1, 1},stride={1, 1},dilation={1, 1},group=1,padding_mode=0],alpha=1,beta=0}, {op=add,alpha=1,beta=0}, {op=relu,alpha=1,beta=0}}](x,main:@3,main:@5,main:#output_0) -> float_type, {50, 6, 224, 224}, {301056, 50176, 224, 1}\n",
      "main:@8 = @return(main:@7)\n",
      "\n",
      "\n",
      "module: \"main\"\n",
      "main:@0 = check_context::migraphx::version_1::gpu::context -> float_type, {}, {}\n",
      "main:@1 = hip::hip_allocate_memory[shape=float_type, {3200}, {1},id=main:scratch] -> float_type, {3200}, {1}\n",
      "main:@2 = hip::hip_copy_literal[id=main:@literal:0] -> float_type, {301056, 64}, {64, 1}\n",
      "abs_1 = @param:abs_1 -> float_type, {50, 6, 224, 224}, {301056, 50176, 224, 1}\n",
      "main:@4 = load[offset=0,end=12800](main:@1) -> float_type, {50, 64}, {64, 1}\n",
      "main:@5 = reshape[dims={50, 301056}](abs_1) -> float_type, {50, 301056}, {301056, 1}\n",
      "main:@6 = gpu::gemm[alpha=1,beta=0,int8_x4_format=1](main:@5,main:@2,main:@4) -> float_type, {50, 64}, {64, 1}\n",
      "main:@7 = hip::hip_copy_literal[id=main:@literal:1] -> float_type, {64}, {1}\n",
      "main:@8 = multibroadcast[out_lens={50, 64}](main:@7) -> float_type, {50, 64}, {0, 1}\n",
      "main:#output_0 = @param:main:#output_0 -> float_type, {50, 64}, {64, 1}\n",
      "main:@10 = gpu::code_object[code_object=13656,symbol_name=add_kernel,global=1024,local=1024,](main:@6,main:@8,main:#output_0) -> float_type, {50, 64}, {64, 1}\n",
      "main:@11 = @return(main:@10)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_mod._run_on_acc_0.program.print()\n",
    "split_mod._run_on_acc_2.program.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we ensure that the converted modules produce the same output as the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_mod = split_mod.cuda()\n",
    "model = model.cuda()\n",
    "sample_inputs = [i.cuda() for i in sample_inputs]\n",
    "\n",
    "torch_out = model(*sample_inputs)\n",
    "lowered_model_out = split_mod(*sample_inputs)\n",
    "\n",
    "torch.testing.assert_close(torch_out,\n",
    "                            lowered_model_out,\n",
    "                            atol=3e-3,\n",
    "                            rtol=1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules that contain MGXModules as submodules can be saved and loaded in the same manner as torch modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(split_mod, 'split_mod.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_split_mod = torch.load('split_mod.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload_mod_out = reload_split_mod(*sample_inputs)\n",
    "\n",
    "torch.testing.assert_close(torch_out,\n",
    "                            reload_mod_out,\n",
    "                            atol=3e-3,\n",
    "                            rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
