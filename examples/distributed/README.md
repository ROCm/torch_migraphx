# Examples using distrubuted workflows
1. Tensor parallel workflow
```
torchrun --nproc_per_node=2 tensor_parallel.py 
```